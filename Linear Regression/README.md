## Linear Regression


Linear Regression is essentially just a best fit line. Given a set of data the algorithm will create a best fit line through those data points.


![Linear Regression](https://github.com/user-attachments/assets/a37ed51d-f60f-405d-9e65-a16ddcca0c46)


This line can be defined by the equation y = m*x + b.

m is the slope. Meaning how much the y value increases for each x value.

b is the y intercept. Where the line crosses the y axis.

We can determine the slope(m) of the line by picking two points on the line (p1 and p2) and using the following equation: m = (y2 - y1) / (x2 - x1) linear regression python

Once the computer has generated this line it will use it to predict certain values.

Note: The examples above are done in 2D space. In reality most of our best fit lines will span across multiple dimensions and therefore will have multiple slope values.

---

![image](https://github.com/user-attachments/assets/43bed061-9f02-4115-a37b-3b145d6aaa8c)




The least squares method is a mathematical approach used in linear regression to find the best-fitting line through a set of data points. The goal is to minimize the sum of the squared differences between the observed values and the values predicted by the linear model.

